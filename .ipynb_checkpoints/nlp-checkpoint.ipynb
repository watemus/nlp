{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Hotel_name</th>\n",
       "      <th>Review_Title</th>\n",
       "      <th>Review_Text</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Park Hyatt</td>\n",
       "      <td>Refuge in Chennai</td>\n",
       "      <td>Excellent room and exercise facility. All arou...</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hilton Chennai</td>\n",
       "      <td>Hilton Chennai</td>\n",
       "      <td>Very comfortable and felt safe. \\r\\nStaff were...</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Royal Regency</td>\n",
       "      <td>No worth the rating shown in websites. Pricing...</td>\n",
       "      <td>Not worth the rating shown. Service is not goo...</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>Good stay</td>\n",
       "      <td>First of all nice &amp; courteous staff, only one ...</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Park Hyatt</td>\n",
       "      <td>Needs improvement</td>\n",
       "      <td>Overall ambience of the hotel is very good. In...</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id         Hotel_name                                       Review_Title  \\\n",
       "0   0         Park Hyatt                                  Refuge in Chennai   \n",
       "1   1     Hilton Chennai                                     Hilton Chennai   \n",
       "2   2  The Royal Regency  No worth the rating shown in websites. Pricing...   \n",
       "3   3             Rivera                                          Good stay   \n",
       "4   4         Park Hyatt                                  Needs improvement   \n",
       "\n",
       "                                         Review_Text  Rating  \n",
       "0  Excellent room and exercise facility. All arou...    80.0  \n",
       "1  Very comfortable and felt safe. \\r\\nStaff were...   100.0  \n",
       "2  Not worth the rating shown. Service is not goo...    71.0  \n",
       "3  First of all nice & courteous staff, only one ...    86.0  \n",
       "4  Overall ambience of the hotel is very good. In...    86.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv', encoding='cp1252')\n",
    "df_test  = pd.read_csv('test.csv', encoding='cp1252')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2351, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2352, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем положительные и отрицательные слова в 2 списка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a+', 'abound', 'abounds', 'abundance', 'abundant', 'accessable',\n",
       "       'accessible', 'acclaim', 'acclaimed', 'acclamation', 'accolade',\n",
       "       'accolades', 'accommodative', 'accomodative', 'accomplish',\n",
       "       'accomplished', 'accomplishment', 'accomplishments', 'accurate',\n",
       "       'accurately'], dtype='<U20')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwords = np.array(open('positive-words.txt', encoding='cp1252').read().split())\n",
    "nwords = np.array(open('negative-words.txt', encoding='cp1252').read().split())\n",
    "pwords[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию подсчета среднего числа колонки по названию отеля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mean_rating(data, coln):\n",
    "    ratings = data[coln]\n",
    "    d  = dict()\n",
    "    di = dict()\n",
    "    for i in range(len(ratings)):\n",
    "        cur = data['Hotel_name'][i]\n",
    "        if cur in d.keys():\n",
    "            d[cur]  += ratings[i]\n",
    "            di[cur] += 1\n",
    "        else:\n",
    "            d[cur]  = ratings[i]\n",
    "            di[cur] = 1\n",
    "    for k in d.keys():\n",
    "        d[k] /= di[k]\n",
    "    ans = np.ones(len(ratings))\n",
    "    for i in range(len(ratings)):\n",
    "        ans[i] = d[data['Hotel_name'][i]]\n",
    "    return ans\n",
    "\n",
    "mean_rating = count_mean_rating(df_train, 'Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = pd.DataFrame({'mr': mean_rating})\n",
    "y = pd.DataFrame({'Rating': df_train['Rating']})\n",
    "#X = pd.get_dummies(X)\n",
    "#print(int(-cross_val_score(LinearRegression(), X, y, cv=5, scoring='neg_mean_squared_error').mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем для каждого слова из pwords и nwords вес из SentiWordNet.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n"
     ]
    }
   ],
   "source": [
    "weights = dict()\n",
    "f = True\n",
    "with open('SentiWordNet.txt') as swn:\n",
    "    lns = swn.readlines()\n",
    "    for i in range(1, len(lns)):\n",
    "        cur = lns[i].split()\n",
    "        if len(cur) > 1 and cur[0] in pwords:\n",
    "            weights[cur[0]] = float(cur[1])\n",
    "        elif len(cur) > 2 and cur[0] in nwords:\n",
    "            weights[cur[0]] = -float(cur[2])\n",
    "        if (len(lns) / i > 0.1 and f):\n",
    "            print(cur[1])\n",
    "            f = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights['awesome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем TF-IDF для заголовков и текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df_train['Review_Title'] = df_train['Review_Title'].fillna('')\n",
    "df_train['Review_Text']  = df_train['Review_Text'].fillna('')\n",
    "\n",
    "corp_title = np.array(df_train['Review_Title'])\n",
    "corp_text  = np.array(df_train['Review_Text'])\n",
    "\n",
    "vectorizer_title = TfidfVectorizer()\n",
    "vectorizer_text  = TfidfVectorizer()\n",
    "Xcorp_title = vectorizer_title.fit_transform(corp_title)\n",
    "Xcorp_text  = vectorizer_text.fit_transform(corp_text)\n",
    "\n",
    "def count_ws(corp, vect):\n",
    "    d = dict()\n",
    "    for i in range(corp.shape[1]):\n",
    "        d[vect.get_feature_names()[i]] = i\n",
    "    return d\n",
    "\n",
    "ws_title_vect = count_ws(Xcorp_title, vectorizer_title)\n",
    "ws_text_vect = count_ws(Xcorp_text, vectorizer_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для заголовка и текста каждого отзыва подсчитаем суммарный вес из TF-IDF и SentiWordNet. Если перед словом из pwords или nwords стоит слово very, more, extremely и т.д. мы услиливаем его вес. Если же перед словом стоит отрицательная частица (not, no, never и тд), то мы перед весом ставим знак минус и прибавляем/вычитаем максимальный вес (если просто поставить знак минус то получиться, что not good лучше чем not awesome, что на самом деле не так)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/watemus/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def makep(data):\n",
    "    ws_title = np.zeros(len(data['Id']))\n",
    "    ws_text  = np.zeros(len(data['Id']))\n",
    "    neg = []\n",
    "    neg = ['no', 'not', 'never', 'without', 'nowhere', 'neither', 'nor', 'isn\\'t', 'didn\\'t']\n",
    "    mor = ['very', 'extremely', 'really', 'more', 'absolute', 'absolutely']\n",
    "    for i in range(len(ws_text)):\n",
    "        prev = ''\n",
    "        if not pd.isna(data['Review_Title'][i]):\n",
    "            for word in nltk.word_tokenize(data['Review_Title'][i]):\n",
    "                if word.lower() in pwords or word.lower() in nwords:\n",
    "                    if prev in neg:\n",
    "                        if word.lower() in nwords:\n",
    "                            ws_title[i] += Xcorp_title.max()\n",
    "                            pass\n",
    "                        else:\n",
    "                            ws_title[i] -= Xcorp_title.max()\n",
    "                            pass\n",
    "                    if word.lower() in weights.keys():\n",
    "                        ws_title[i] += weights[word.lower()]\n",
    "                        if prev in mor:\n",
    "                            ws_title[i] += weights[word.lower()]\n",
    "                    if word in ws_title_vect.keys():\n",
    "                        if word.lower() in nwords:\n",
    "                            ws_title[i] -= Xcorp_title[i, ws_title_vect[word]]\n",
    "                            if prev in mor:\n",
    "                                ws_title[i] -= Xcorp_title[i, ws_title_vect[word]]\n",
    "                        else:\n",
    "                            ws_title[i] += Xcorp_title[i, ws_title_vect[word]]\n",
    "                            if prev in mor:\n",
    "                                ws_title[i] += Xcorp_title[i, ws_title_vect[word]]\n",
    "                prev = word.lower()\n",
    "            \n",
    "        prev = ''\n",
    "        if pd.isna(data['Review_Text'][i]): continue\n",
    "        for word in nltk.word_tokenize(data['Review_Text'][i]):\n",
    "            if word.lower() in pwords or word.lower() in nwords:\n",
    "                if prev in neg:\n",
    "                    if word.lower() in nwords:\n",
    "                        ws_text[i] += Xcorp_text.max()\n",
    "                        pass\n",
    "                    else:\n",
    "                        ws_text[i] -= Xcorp_text.max() \n",
    "                        pass\n",
    "                if word.lower() in weights.keys():\n",
    "                    ws_text[i] += weights[word.lower()]\n",
    "                    if prev in mor:\n",
    "                            ws_text[i] += weights[word.lower()]\n",
    "                if word in ws_text_vect.keys():\n",
    "                    if word.lower() in nwords:\n",
    "                        ws_text[i] -= Xcorp_text[i, ws_text_vect[word]]\n",
    "                        if prev in mor:\n",
    "                            ws_text[i] -= Xcorp_text[i, ws_text_vect[word]]\n",
    "                    else:\n",
    "                        ws_text[i] += Xcorp_text[i, ws_text_vect[word]]\n",
    "                        if prev in mor:\n",
    "                            ws_text[i] += Xcorp_text[i, ws_text_vect[word]]\n",
    "            prev = word.lower()\n",
    "    return ws_title, ws_text\n",
    "\n",
    "ws_title, ws_text = makep(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.81657316,  2.36439832, -1.33335188,  0.38656196,  0.67826538,\n",
       "        0.95989831,  3.0749068 , -0.36112393,  0.22700973, -0.44470738,\n",
       "        3.0677214 ,  2.15981046, -1.04369424, -0.18532364, -1.74433313,\n",
       "        0.45014109,  2.07022766, -0.45031318,  0.33854771, -0.52373493,\n",
       "       -0.69038051,  4.77160916,  1.19152315,  1.57317388,  0.        ,\n",
       "        1.86189628,  1.12617914,  0.9944533 ,  0.47320976,  0.7555258 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_text[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим еще пару признаков (сумму суммарных весов текста и заголовка, средние разные суммарные веса по заголовку) и сделаем кросс-валидацию на RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mr</th>\n",
       "      <th>ws_text</th>\n",
       "      <th>ws_title</th>\n",
       "      <th>sws</th>\n",
       "      <th>mws_text</th>\n",
       "      <th>mws_title</th>\n",
       "      <th>msws</th>\n",
       "      <th>smws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.924528</td>\n",
       "      <td>2.816573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.816573</td>\n",
       "      <td>1.295506</td>\n",
       "      <td>0.346771</td>\n",
       "      <td>1.642277</td>\n",
       "      <td>1.642277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.527778</td>\n",
       "      <td>2.364398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.364398</td>\n",
       "      <td>1.805128</td>\n",
       "      <td>0.544207</td>\n",
       "      <td>2.349336</td>\n",
       "      <td>2.349336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.555556</td>\n",
       "      <td>-1.333352</td>\n",
       "      <td>-0.735928</td>\n",
       "      <td>-2.069280</td>\n",
       "      <td>0.297394</td>\n",
       "      <td>0.085757</td>\n",
       "      <td>0.383151</td>\n",
       "      <td>0.383151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.083333</td>\n",
       "      <td>0.386562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.386562</td>\n",
       "      <td>1.736056</td>\n",
       "      <td>0.157511</td>\n",
       "      <td>1.893568</td>\n",
       "      <td>1.893568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.924528</td>\n",
       "      <td>0.678265</td>\n",
       "      <td>1.085523</td>\n",
       "      <td>1.763788</td>\n",
       "      <td>1.295506</td>\n",
       "      <td>0.346771</td>\n",
       "      <td>1.642277</td>\n",
       "      <td>1.642277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mr   ws_text  ws_title       sws  mws_text  mws_title      msws  \\\n",
       "0  79.924528  2.816573  0.000000  2.816573  1.295506   0.346771  1.642277   \n",
       "1  90.527778  2.364398  0.000000  2.364398  1.805128   0.544207  2.349336   \n",
       "2  66.555556 -1.333352 -0.735928 -2.069280  0.297394   0.085757  0.383151   \n",
       "3  84.083333  0.386562  0.000000  0.386562  1.736056   0.157511  1.893568   \n",
       "4  79.924528  0.678265  1.085523  1.763788  1.295506   0.346771  1.642277   \n",
       "\n",
       "       smws  \n",
       "0  1.642277  \n",
       "1  2.349336  \n",
       "2  0.383151  \n",
       "3  1.893568  \n",
       "4  1.642277  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "X['ws_text']  = ws_text\n",
    "X['ws_title'] = ws_title\n",
    "X['sws'] = X['ws_text'] + X['ws_title']\n",
    "X['mr'] = mean_rating\n",
    "X['Hotel_name'] = df_train['Hotel_name']\n",
    "X['mws_text'] = count_mean_rating(X, 'ws_text')\n",
    "X['mws_title'] = count_mean_rating(X, 'ws_title')\n",
    "X['msws'] = count_mean_rating(X, 'sws')\n",
    "X['smws'] = X['mws_title'] + X['mws_text']\n",
    "del X['Hotel_name']\n",
    "y = np.array(y)\n",
    "y = column_or_1d(y, warn=True)\n",
    "#print((X['mws_title']<-9.1).sum())\n",
    "print(int(-cross_val_score(RandomForestRegressor(n_estimators=200, max_depth=50), X, y, cv=5, scoring='neg_mean_squared_error', n_jobs=5).mean()))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
